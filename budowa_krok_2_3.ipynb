{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Milestone II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/lila/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/lila/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/lila/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "import string\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import Counter\n",
    "from textstat import textstat\n",
    "from sklearn.utils import resample\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# NLTK imports\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# NLTK downloads\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"vader_lexicon\")\n",
    "\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Comment_preprocessed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the creator of monopoly would be speechless ab...</td>\n",
       "      <td>negative</td>\n",
       "      <td>creator monopoly speechless</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sometimes im just taking my test and the voice...</td>\n",
       "      <td>negative</td>\n",
       "      <td>taking test voice scare loooool coming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>even when andy isnt trying to be a genius he is</td>\n",
       "      <td>neutral</td>\n",
       "      <td>andy genius</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>its just usual trimming of the fluff when exce...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>usual trimming fluff excess liquidity withdraw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mom wake your ass up for classes me oh nah nah...</td>\n",
       "      <td>negative</td>\n",
       "      <td>mom wake as class meeting bed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment Sentiment  \\\n",
       "0  the creator of monopoly would be speechless ab...  negative   \n",
       "1  sometimes im just taking my test and the voice...  negative   \n",
       "2    even when andy isnt trying to be a genius he is   neutral   \n",
       "3  its just usual trimming of the fluff when exce...   neutral   \n",
       "4  mom wake your ass up for classes me oh nah nah...  negative   \n",
       "\n",
       "                                Comment_preprocessed  \n",
       "0                        creator monopoly speechless  \n",
       "1             taking test voice scare loooool coming  \n",
       "2                                        andy genius  \n",
       "3  usual trimming fluff excess liquidity withdraw...  \n",
       "4                      mom wake as class meeting bed  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"YoutubeCommentsDataSet_Balanced.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ramka df zawiera kolumny Comment, Sentiment oraz Comment_preprocessed. Zbiór ten jest zbalansowany pod względem sentymentów, oczysczony i pozbawiony duplikatów.\n",
    "Comment_preprocessed zawiera komentarze z usuniętymi stopwords. Pozostawiłyśmy kolumnę Comment bez zmian, gdyż będziemy jej potrzebować do stworzenia niektórych cech  istotnych w budowie modelu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inżynieria cech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W kontekście naszych danych stwierdziłyśmy, że przydatne będą następujące cechy:\n",
    "- Sentiment_Score_nltk (ciągły wskaźnik sentymentu komentarza o warotściach [-1, 1])\n",
    "- Comment_length (długość komentarza)\n",
    "- Starts_with_i (czy komentarz zaczyna się od I)\n",
    "- Personal_Pronoun_count (liczba zaimków osobowych, takich jak he, she, i, etc.)\n",
    "- Number_of_phrases (czyli podział komentarza według spójników \"but\", \"and\", \"because\")\n",
    "- Avg_phrase_length (średnia długość frazy)\n",
    "- Number_of_words (liczba słów)\n",
    "- Avg_word_length (średnia długość słów)\n",
    "- Unique_word_ratio (stosunek liczby unikalnych słów do wszystkich słów, im większa tym bardziej rozbudowane słownictwo)\n",
    "- Readibility_Score (wskaźnik czytelności tekstu mierzony za pomocą Flesch Reading Ease)\n",
    "- Negation_Count (ilość negacji w komentarzu, czyli słów, które wprowadzają zaprzeczenie np. \"not\",\"never\",\"nobody\",\"dont\" itp.)\n",
    "- Rare_Word_Count (Liczenie rzadkich słów na podstawie ich częstotliwości w całym zbiorze danych)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zmienna Sentiment_Score_nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funkcja do obliczania Sentiment Score za pomocą NLTK\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "def sentiment_score(comment):\n",
    "    return sia.polarity_scores(comment)['compound']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zmienna Personal_Pronun_Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funkcja do liczenia liczby zaimków osobistych\n",
    "personal_pronouns = {\"i\", \"me\", \"my\", \"mine\", \"myself\", \"we\", \"us\", \"our\", \"ours\", \"ourselves\",\n",
    "                     \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\",\n",
    "                     \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\",\n",
    "                     \"theirs\", \"themselves\"}\n",
    "\n",
    "def count_personal_pronouns(comment):\n",
    "    words = word_tokenize(comment.lower())\n",
    "    return sum(1 for word in words if word in personal_pronouns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zmienne Number_of_phrases, Number_of_words, Avg_phrase_length, Avg_word_length, Unique_word_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funkcja do analizy złożoności zdań (np. liczba fraz, słów)\n",
    "connectors = [\"and\", \"but\", \"so\", \"because\", \"which\", \"that\", \"then\", \"if\", \"or\"]\n",
    "def sentence_complexity(comment):\n",
    "    words = word_tokenize(comment)\n",
    "    phrases = re.split(r'\\b(?:' + '|'.join(connectors) + r')\\b', comment)\n",
    "\n",
    "    num_words = len(words)\n",
    "    num_phrases = len(phrases)\n",
    "\n",
    "    avg_word_length = np.mean([len(word) for word in words]) if words else 0\n",
    "    avg_phrase_length = num_words / num_phrases if num_phrases > 0 else 0\n",
    "    unique_word_ratio = len(set(words)) / num_words if num_words > 0 else 0\n",
    "\n",
    "    return {\n",
    "        \"Number_of_phrases\": num_phrases,\n",
    "        \"Number_of_words\": num_words,\n",
    "        \"Avg_phrase_length\": avg_phrase_length,\n",
    "        \"Avg_word_length\": avg_word_length,\n",
    "        \"Unique_word_ratio\": unique_word_ratio\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zmienna Readability_Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funkcja do obliczania readability score\n",
    "def readability_score(comment):\n",
    "    return textstat.flesch_reading_ease(comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zmienna Negation_Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funkcja do liczenia negacji\n",
    "def negation_count(comment):\n",
    "    negations = {\"not\", \"never\", \"no\", \"none\", \"cannot\", \"nothing\",\"dont\",\"nah\",'wont','cant','doesnt','shouldnt',\"shouldn't\",\"doesn't\"\n",
    "                 \"don't\",\"won't\",\"wouldn't\", \"can't\",\"nobody\",'neither','nope',\"ain't\",\"nowhere\",'wouldnt'}\n",
    "    words = word_tokenize(comment.lower())\n",
    "    return sum(1 for word in words if word in negations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zmienna Rare_Word_Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funkcja do liczenia rzadkich słów\n",
    "def rare_word_count(comment, all_words):\n",
    "    words = word_tokenize(comment.lower())\n",
    "    rare_words = [word for word in words if all_words[word] < 10]  # Możemy dostosować próg (tutaj <10)\n",
    "    return len(rare_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przygotowujemy cechy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funkcja do przygotowania cech\n",
    "def prepare_features(df):\n",
    "    # Dodajemy cechy do DataFrame\n",
    "    df['Sentiment_Score_nltk'] = df['Comment'].apply(sentiment_score)\n",
    "    df['Starts_with_i'] = df['Comment'].str.startswith(\"i\")\n",
    "    df['Comment_Length'] = df['Comment'].str.len()\n",
    "    \n",
    "    sentiment_mapping = {'negative': -1, 'neutral': 0, 'positive': 1}\n",
    "    df['Sentiment_num'] = df['Sentiment'].map(sentiment_mapping)\n",
    "\n",
    "    df[\"Personal_Pronoun_count\"] = df[\"Comment\"].apply(count_personal_pronouns)\n",
    "    df[\"Readability_Score\"] = df[\"Comment\"].apply(readability_score)\n",
    "    df[\"Negation_Count\"] = df[\"Comment\"].apply(negation_count)\n",
    "\n",
    "    df_complexity = df[\"Comment\"].apply(lambda x: sentence_complexity(x))\n",
    "    df_complexity = pd.DataFrame(df_complexity.tolist())\n",
    "    df = pd.concat([df, df_complexity], axis=1)\n",
    "\n",
    "    # Liczenie rzadkich słów\n",
    "    all_words = Counter(' '.join(df['Comment']).lower().split())\n",
    "    df['Rare_Word_Count'] = df['Comment'].apply(lambda x: rare_word_count(x, all_words))\n",
    "\n",
    "    #TF-IDF Embeddings**\n",
    "    tfidf = TfidfVectorizer(max_features=300)\n",
    "    tfidf_matrix = tfidf.fit_transform(df['Comment']).toarray()\n",
    "    tfidf_df = pd.DataFrame(tfidf_matrix, columns=[f\"tfidf_{i}\" for i in range(tfidf_matrix.shape[1])])\n",
    "    \n",
    "    df = pd.concat([df.reset_index(drop=True), tfidf_df], axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to apply TF-IDF embedding on preprocessed comments\n",
    "def apply_tfidf(df):\n",
    "    tfidf = TfidfVectorizer(max_features=300)\n",
    "    tfidf_matrix = tfidf.fit_transform(df['Comment_preprocessed']).toarray()\n",
    "    tfidf_df = pd.DataFrame(tfidf_matrix, columns=[f\"tfidf_{i}\" for i in range(tfidf_matrix.shape[1])])\n",
    "    \n",
    "    return pd.concat([df.reset_index(drop=True), tfidf_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Budujemy pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_feature_pipeline():\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"text_features\", FunctionTransformer(prepare_features), ['Comment']),\n",
    "            (\"tfidf_features\", FunctionTransformer(apply_tfidf), ['Comment_preprocessed'])\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor)\n",
    "    ])\n",
    "    \n",
    "    return pipeline\n",
    "\n",
    "# Tworzenie i zapisanie pipeline\n",
    "pipeline = build_feature_pipeline()\n",
    "\n",
    "with open(\"feature_pipeline.pkl\", \"wb\") as file:\n",
    "    pickle.dump(pipeline, file) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplikujemy wszystkie features na naszym zbiorze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Comment_preprocessed</th>\n",
       "      <th>Sentiment_Score_nltk</th>\n",
       "      <th>Starts_with_i</th>\n",
       "      <th>Comment_Length</th>\n",
       "      <th>Sentiment_num</th>\n",
       "      <th>Personal_Pronoun_count</th>\n",
       "      <th>Readability_Score</th>\n",
       "      <th>Negation_Count</th>\n",
       "      <th>...</th>\n",
       "      <th>tfidf_290</th>\n",
       "      <th>tfidf_291</th>\n",
       "      <th>tfidf_292</th>\n",
       "      <th>tfidf_293</th>\n",
       "      <th>tfidf_294</th>\n",
       "      <th>tfidf_295</th>\n",
       "      <th>tfidf_296</th>\n",
       "      <th>tfidf_297</th>\n",
       "      <th>tfidf_298</th>\n",
       "      <th>tfidf_299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the creator of monopoly would be speechless ab...</td>\n",
       "      <td>negative</td>\n",
       "      <td>creator monopoly speechless</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>False</td>\n",
       "      <td>58</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>52.87</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.480023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sometimes im just taking my test and the voice...</td>\n",
       "      <td>negative</td>\n",
       "      <td>taking test voice scare loooool coming</td>\n",
       "      <td>0.0258</td>\n",
       "      <td>False</td>\n",
       "      <td>98</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>86.03</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>even when andy isnt trying to be a genius he is</td>\n",
       "      <td>neutral</td>\n",
       "      <td>andy genius</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>False</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>68.77</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>its just usual trimming of the fluff when exce...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>usual trimming fluff excess liquidity withdraw...</td>\n",
       "      <td>0.2023</td>\n",
       "      <td>True</td>\n",
       "      <td>218</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>53.21</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.12139</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mom wake your ass up for classes me oh nah nah...</td>\n",
       "      <td>negative</td>\n",
       "      <td>mom wake as class meeting bed</td>\n",
       "      <td>-0.7579</td>\n",
       "      <td>False</td>\n",
       "      <td>88</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>92.46</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.456756</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 316 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment Sentiment  \\\n",
       "0  the creator of monopoly would be speechless ab...  negative   \n",
       "1  sometimes im just taking my test and the voice...  negative   \n",
       "2    even when andy isnt trying to be a genius he is   neutral   \n",
       "3  its just usual trimming of the fluff when exce...   neutral   \n",
       "4  mom wake your ass up for classes me oh nah nah...  negative   \n",
       "\n",
       "                                Comment_preprocessed  Sentiment_Score_nltk  \\\n",
       "0                        creator monopoly speechless                0.0000   \n",
       "1             taking test voice scare loooool coming                0.0258   \n",
       "2                                        andy genius                0.0000   \n",
       "3  usual trimming fluff excess liquidity withdraw...                0.2023   \n",
       "4                      mom wake as class meeting bed               -0.7579   \n",
       "\n",
       "   Starts_with_i  Comment_Length  Sentiment_num  Personal_Pronoun_count  \\\n",
       "0          False              58             -1                       0   \n",
       "1          False              98             -1                       2   \n",
       "2          False              47              0                       1   \n",
       "3           True             218              0                       4   \n",
       "4          False              88             -1                       3   \n",
       "\n",
       "   Readability_Score  Negation_Count  ...  tfidf_290  tfidf_291  tfidf_292  \\\n",
       "0              52.87               0  ...        0.0        0.0   0.480023   \n",
       "1              86.03               0  ...        0.0        0.0   0.000000   \n",
       "2              68.77               0  ...        0.0        0.0   0.000000   \n",
       "3              53.21               0  ...        0.0        0.0   0.000000   \n",
       "4              92.46               5  ...        0.0        0.0   0.000000   \n",
       "\n",
       "   tfidf_293  tfidf_294  tfidf_295  tfidf_296  tfidf_297  tfidf_298  tfidf_299  \n",
       "0        0.0        0.0        0.0        0.0    0.00000   0.000000        0.0  \n",
       "1        0.0        0.0        0.0        0.0    0.00000   0.000000        0.0  \n",
       "2        0.0        0.0        0.0        0.0    0.00000   0.000000        0.0  \n",
       "3        0.0        0.0        0.0        0.0    0.12139   0.000000        0.0  \n",
       "4        0.0        0.0        0.0        0.0    0.00000   0.456756        0.0  \n",
       "\n",
       "[5 rows x 316 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = prepare_features(df)\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
